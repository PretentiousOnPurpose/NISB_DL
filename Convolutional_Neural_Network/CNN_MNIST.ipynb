{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\" ,one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_var(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_strides = [1, 1, 1, 1]\n",
    "pool_2by2 = [1, 2, 2, 1]\n",
    "pool_1by1 = [1 , 1 , 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x , shape):\n",
    "    w = random_var(shape)\n",
    "    b = random_var([shape[3]])\n",
    "    return tf.nn.relu(tf.nn.conv2d(input=x , filter=w , strides=conv_strides , padding='SAME') + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_conn(x , num):\n",
    "    input_size = int(x.get_shape()[1])\n",
    "    w = random_var((input_size, num))\n",
    "    b = random_var((1, num))\n",
    "    return tf.matmul(x , w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32 , shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32 , shape=[None , 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = tf.reshape(X , [-1 , 28 , 28 , 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = conv2d(x_img , shape = [5, 5, 1 ,32])\n",
    "pool1 = tf.nn.max_pool(cnn1 , ksize= pool_2by2 , strides= pool_2by2 , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = conv2d(pool1 , shape = [5, 5, 32 ,64])\n",
    "pool2 = tf.nn.max_pool(cnn2 , ksize= pool_2by2 , strides= pool_2by2 , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = conv2d(pool2 , shape = [5, 5, 64 ,128])\n",
    "pool3 = tf.nn.max_pool(cnn3 , ksize= pool_2by2 , strides= pool_2by2 , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4 = conv2d(pool3 , shape = [5, 5, 128 ,192])\n",
    "pool4 = tf.nn.max_pool(cnn4 , ksize= pool_2by2 , strides= pool_2by2 , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat3 = tf.reshape(pool4 , [-1 , 2*2*192])\n",
    "full_conn1 = tf.nn.relu(full_conn(flat3 , 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_p = tf.placeholder(tf.float32)\n",
    "full_conn1_drop = tf.nn.dropout(x = full_conn1 , keep_prob= drop_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = full_conn(full_conn1_drop , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_ , labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=0.00005)\n",
    "exe = opt.minimize(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy:  0.0978\n",
      "\n",
      "\n",
      "Iteration: 500\n",
      "Accuracy:  0.5818\n",
      "\n",
      "\n",
      "Iteration: 1000\n",
      "Accuracy:  0.7458\n",
      "\n",
      "\n",
      "Iteration: 1500\n",
      "Accuracy:  0.815\n",
      "\n",
      "\n",
      "Iteration: 2000\n",
      "Accuracy:  0.846\n",
      "\n",
      "\n",
      "Iteration: 2500\n",
      "Accuracy:  0.8696\n",
      "\n",
      "\n",
      "Iteration: 3000\n",
      "Accuracy:  0.888\n",
      "\n",
      "\n",
      "Iteration: 3500\n",
      "Accuracy:  0.898\n",
      "\n",
      "\n",
      "Iteration: 4000\n",
      "Accuracy:  0.9062\n",
      "\n",
      "\n",
      "Iteration: 4500\n",
      "Accuracy:  0.9134\n",
      "\n",
      "\n",
      "Iteration: 5000\n",
      "Accuracy:  0.9218\n",
      "\n",
      "\n",
      "Iteration: 5500\n",
      "Accuracy:  0.9244\n",
      "\n",
      "\n",
      "Iteration: 6000\n",
      "Accuracy:  0.9264\n",
      "\n",
      "\n",
      "Iteration: 6500\n",
      "Accuracy:  0.9328\n",
      "\n",
      "\n",
      "Iteration: 7000\n",
      "Accuracy:  0.9378\n",
      "\n",
      "\n",
      "Iteration: 7500\n",
      "Accuracy:  0.9378\n",
      "\n",
      "\n",
      "Iteration: 8000\n",
      "Accuracy:  0.9388\n",
      "\n",
      "\n",
      "Iteration: 8500\n",
      "Accuracy:  0.941\n",
      "\n",
      "\n",
      "Iteration: 9000\n",
      "Accuracy:  0.9438\n",
      "\n",
      "\n",
      "Iteration: 9500\n",
      "Accuracy:  0.9456\n",
      "\n",
      "\n",
      "Iteration: 10000\n",
      "Accuracy:  0.9462\n",
      "\n",
      "\n",
      "Iteration: 10500\n",
      "Accuracy:  0.9454\n",
      "\n",
      "\n",
      "Iteration: 11000\n",
      "Accuracy:  0.9444\n",
      "\n",
      "\n",
      "Iteration: 11500\n",
      "Accuracy:  0.9448\n",
      "\n",
      "\n",
      "Iteration: 12000\n",
      "Accuracy:  0.9464\n",
      "\n",
      "\n",
      "Iteration: 12500\n",
      "Accuracy:  0.9482\n",
      "\n",
      "\n",
      "Iteration: 13000\n",
      "Accuracy:  0.9502\n",
      "\n",
      "\n",
      "Iteration: 13500\n",
      "Accuracy:  0.9482\n",
      "\n",
      "\n",
      "Iteration: 14000\n",
      "Accuracy:  0.952\n",
      "\n",
      "\n",
      "Iteration: 14500\n",
      "Accuracy:  0.9522\n",
      "\n",
      "\n",
      "Iteration: 15000\n",
      "Accuracy:  0.9514\n",
      "\n",
      "\n",
      "Iteration: 15500\n",
      "Accuracy:  0.9494\n",
      "\n",
      "\n",
      "Iteration: 16000\n",
      "Accuracy:  0.9508\n",
      "\n",
      "\n",
      "Iteration: 16500\n",
      "Accuracy:  0.9502\n",
      "\n",
      "\n",
      "Iteration: 17000\n",
      "Accuracy:  0.9492\n",
      "\n",
      "\n",
      "Iteration: 17500\n",
      "Accuracy:  0.9514\n",
      "\n",
      "\n",
      "Iteration: 18000\n",
      "Accuracy:  0.9492\n",
      "\n",
      "\n",
      "Iteration: 18500\n",
      "Accuracy:  0.9512\n",
      "\n",
      "\n",
      "Iteration: 19000\n",
      "Accuracy:  0.9502\n",
      "\n",
      "\n",
      "Iteration: 19500\n",
      "Accuracy:  0.9544\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 20000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x , batch_y = mnist.train.next_batch(50)\n",
    "        \n",
    "        sess.run(exe,feed_dict={X:batch_x,Y:batch_y,drop_p:0.6})\n",
    "        if i%500 == 0:\n",
    "            print('Iteration: {}'.format(i))\n",
    "\n",
    "            matches = tf.equal(tf.argmax(y_,1),tf.argmax(Y,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(\"Accuracy: \",sess.run(acc,feed_dict={X:mnist.validation.images,Y:mnist.validation.labels,drop_p:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(N):\n",
    "    sess = tf.InteractiveSession()\n",
    "    z = sess.run(y_ , feed_dict={X:mnist.test.images[N].reshape((1 , 784)) ,drop_p:1.0})\n",
    "    return \"It's \" + str(np.argmax(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x680bdbf748>"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+0hGcD70REgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6818054eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[144].reshape((28 , 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's 7\""
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict(144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
